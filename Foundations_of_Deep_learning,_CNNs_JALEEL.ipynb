{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jelade/deep-learning/blob/main/Foundations_of_Deep_learning%2C_CNNs_JALEEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Convolutional networks\n",
        "In this tutorial, you will implement a simple convolutional neural network (CNN) with pytorch to classifiy images of handwritten digits.\n",
        "\n",
        "**Make sure you are setting the runtime to GPU**\n",
        "\n",
        "\n",
        "This tutorial is based on convnet turorials from AMMI computer vision course 2021"
      ],
      "metadata": {
        "id": "NgGGfPXpgoce"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mJmPZ_YpgQqi"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import PIL\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage.transform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useful methods for visualization"
      ],
      "metadata": {
        "id": "fzr92rXWhr1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def show(img):\n",
        "    \"\"\"Show PyTorch tensor img as an image in matplotlib.\"\"\"\n",
        "    npimg = img.cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
        "    plt.grid(False)\n",
        "    plt.gca().axis('off')\n",
        "\n",
        "def display_thumb(img):\n",
        "  display.display(transforms.Resize(128)(img))"
      ],
      "metadata": {
        "id": "MxORyelAhM6k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Oq35Ut-7hwK0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training and test dataset.\n",
        "mnist_train = datasets.MNIST('/tmp/mnist', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST('/tmp/mnist', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Size of the batches the data loader will produce.\n",
        "batch_size = 64\n",
        "\n",
        "# This creates the dataloaders.\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giPNFPQGh4Ry",
        "outputId": "84e447c6-5819-4479-a267-71919e828607"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 126465657.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 104157948.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 42531849.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6633192.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(mnist_train))\n",
        "print(f\"Image label:{label}\")\n",
        "show(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VW24BkxRGEpj",
        "outputId": "cc2e0bbd-41d8-4e2f-8638-d5a48307130c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image label:5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIkplDHTAUj3",
        "outputId": "25a7cca5-470e-498c-fe8b-33af2c5307ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function \n",
        "def train(model, criterion, data_loader, optimizer, num_epochs):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
        "    \n",
        "    # Make sure model is in training mode.\n",
        "    model.train()\n",
        "    \n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model.to(device)\n",
        "    \n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "    \n",
        "    # Loop over epochs.\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "      # Loop over data.\n",
        "      for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            \n",
        "          # Forward pass.\n",
        "          output = model(data.to(device))\n",
        "          loss = criterion(output.to(device), target.to(device))\n",
        "          \n",
        "          # Backward pass.\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          # NOTE: It is important to call .item() on the loss before summing.\n",
        "          if ema_loss is None:\n",
        "            ema_loss = loss.item()\n",
        "          else:\n",
        "            ema_loss += (loss.item() - ema_loss) * 0.01 \n",
        "          \n",
        "      # Print out progress the end of epoch.\n",
        "      print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
        "            epoch, ema_loss),\n",
        "      )\n",
        "              \n",
        "# Testing Function               \n",
        "def test(model, data_loader):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Loop over test data.\n",
        "        for data, target in data_loader:\n",
        "          \n",
        "            # Forward pass.\n",
        "            output = model(data.to(device))\n",
        "            \n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "            # Count number of correct predictions.\n",
        "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # Print test accuracy.\n",
        "    percent = 100. * correct / len(data_loader.dataset)\n",
        "    print(f'Accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n",
        "    return percent\n",
        "   "
      ],
      "metadata": {
        "id": "YPtPP-Vyh6qF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvNet Model"
      ],
      "metadata": {
        "id": "DzWNJMhiiWl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import ReLU\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  \"\"\"Simple convolutional network.\"\"\"\n",
        "  \n",
        "  def __init__(self, image_side_size, num_classes, in_channels=1):\n",
        "      super(ConvolutionalNetwork, self).__init__()\n",
        "      \n",
        "      self.in_channels = in_channels\n",
        "      self.num_classes = num_classes\n",
        "      self.image_side_size = image_side_size\n",
        "      # Fill these in:\n",
        "      ##########################################################################\n",
        "      # TODO: Implement a convulutional and a linear part.                     #\n",
        "      # Hint: see forward() to understand how they should work together.       #\n",
        "      # Hint: use the method get_conv_network_output to get the size of the input to the linear part\n",
        "      ##########################################################################       \n",
        "\n",
        "      # Define the convolution part, self.conv_network, you can use parameters in the slides as a starting point\n",
        "      # Get the output size from the convolution part using the method get_conv_network_output\n",
        "      # Define the linear part, self.linear\n",
        "      self.conv_network = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = self.in_channels,out_channels = 16,  kernel_size = 5),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride = 2),\n",
        "          nn.Conv2d(in_channels = 16,out_channels = 32,  kernel_size = 5),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "      )\n",
        "\n",
        "  \n",
        "      \n",
        "\n",
        "      self.mlp = nn.Sequential(\n",
        "          nn.Linear(self.get_conv_network_output(), 64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64, self.num_classes),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "  def forward(self, x):\n",
        "      x = self.conv_network(x)\n",
        "      x = self.mlp(x.view(x.size(0), -1))\n",
        "      return x\n",
        "\n",
        "  def get_conv_network_output(self, ):\n",
        "      dummy_x = torch.zeros(1, self.in_channels, self.image_side_size, self.image_side_size)\n",
        "      conv_output = self.conv_network(dummy_x)\n",
        "      conv_output_size = torch.prod(torch.tensor(conv_output.shape))\n",
        "      return conv_output_size\n",
        "\n",
        "    \n",
        "# Create and train convolutional network.\n",
        "# The accuracy should be around 96%.\n",
        "\n",
        "###########################################################################\n",
        "# TODO: Create criterion and optimize here.                               #\n",
        "###########################################################################\n",
        "model = ConvolutionalNetwork(image_side_size = 28, num_classes = 10, in_channels=1)\n",
        "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "###########################################################################\n",
        "# TODO: Train the model and test it on the test set\n",
        "###########################################################################\n",
        "train(model, criterion, train_loader, optimizer, num_epochs)"
      ],
      "metadata": {
        "id": "2tSLf0tHiRu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8951de3d-2fef-48b2-d92a-ee343d32fcdd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 \tLoss: 46.846282\n",
            "Train Epoch: 1 \tLoss: 45.239664\n",
            "Train Epoch: 2 \tLoss: 45.090048\n",
            "Train Epoch: 3 \tLoss: 43.400771\n",
            "Train Epoch: 4 \tLoss: 43.832156\n",
            "Train Epoch: 5 \tLoss: 43.514535\n",
            "Train Epoch: 6 \tLoss: 43.530369\n",
            "Train Epoch: 7 \tLoss: 43.820365\n",
            "Train Epoch: 8 \tLoss: 43.038723\n",
            "Train Epoch: 9 \tLoss: 43.435490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the testing accuracy it should be around 96%\n",
        "\n",
        "test(model, test_loader)"
      ],
      "metadata": {
        "id": "FQMzhVk8jtab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3677dfdd-d20d-481c-d46b-47d56f829e3d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 8000 / 10000 (80%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}